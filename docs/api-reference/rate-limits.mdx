---
title: 'Rate Limits'
description: 'Understanding and handling API rate limits'
---

# Rate Limits

Learn about WebLinq's rate limiting system and how to handle rate-limited requests effectively.

## Overview

<Note>Rate limits are based on your subscription plan and are enforced per API key.</Note>

<CardGroup cols={2}>
  <Card title="Free Tier" icon="gauge-simple">
    - 60 requests per minute - 1,000 requests per day - No concurrent requests
  </Card>

  <Card title="Developer" icon="gauge-simple-med">
    - 300 requests per minute - 10,000 requests per day - 5 concurrent requests
  </Card>

  <Card title="Business" icon="gauge-simple-high">
    - 1,000 requests per minute - 50,000 requests per day - 20 concurrent requests
  </Card>

  <Card title="Enterprise" icon="gauge-max">
    - Custom rate limits - Custom daily quota - Unlimited concurrent requests
  </Card>
</CardGroup>

## Rate Limit Headers

All API responses include rate limit information in the headers:

```http
X-RateLimit-Limit: 60           # Total requests allowed per window
X-RateLimit-Remaining: 45       # Remaining requests in current window
X-RateLimit-Reset: 1625097600   # Timestamp when the limit resets
```

## Handling Rate Limits

When you exceed your rate limit, you'll receive a `429 Too Many Requests` response:

```json
{
  "error": {
    "code": "rate_limit_exceeded",
    "message": "Rate limit exceeded. Please retry after 60 seconds.",
    "retry_after": 60
  }
}
```

### Best Practices

<AccordionGroup>
<Accordion title="Implement Exponential Backoff" icon="clock-rotate-left">
Use exponential backoff to handle rate limits gracefully:

```javascript
async function makeRequest(url, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, {
        headers: { Authorization: 'Bearer YOUR_API_KEY' },
      });

      if (response.status === 429) {
        const retryAfter = response.headers.get('Retry-After');
        await sleep(retryAfter * 1000);
        continue;
      }

      return await response.json();
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await sleep(Math.pow(2, i) * 1000);
    }
  }
}
```

<Tip>
Always respect the `Retry-After` header value when provided.
</Tip>
</Accordion>

<Accordion title="Use Request Queuing" icon="list-check">
Implement a request queue to manage your API calls:

```javascript
class RequestQueue {
  constructor(rateLimit = 60) {
    this.queue = [];
    this.rateLimit = rateLimit;
    this.processing = false;
  }

  async add(request) {
    return new Promise((resolve, reject) => {
      this.queue.push({ request, resolve, reject });
      if (!this.processing) this.process();
    });
  }

  async process() {
    this.processing = true;
    while (this.queue.length > 0) {
      const { request, resolve, reject } = this.queue.shift();
      try {
        const result = await request();
        resolve(result);
      } catch (error) {
        reject(error);
      }
      await sleep(1000 / this.rateLimit);
    }
    this.processing = false;
  }
}

// Usage
const queue = new RequestQueue(60);
queue.add(() => makeRequest('https://api.weblinq.dev/v1/web/content'));
```

</Accordion>

<Accordion title="Batch Requests" icon="layer-group">
Group multiple requests together to optimize your rate limit usage:

```javascript
async function batchRequests(urls, batchSize = 10) {
  const results = [];

  for (let i = 0; i < urls.length; i += batchSize) {
    const batch = urls.slice(i, i + batchSize);
    const batchPromises = batch.map((url) => makeRequest(url));

    try {
      const batchResults = await Promise.all(batchPromises);
      results.push(...batchResults);

      // Rate limit pause between batches
      if (i + batchSize < urls.length) {
        await sleep(1000);
      }
    } catch (error) {
      console.error(`Batch ${i / batchSize} failed:`, error);
    }
  }

  return results;
}
```

<Warning>
Be careful with concurrent requests to avoid hitting rate limits.
</Warning>
</Accordion>

<Accordion title="Monitor Usage" icon="chart-line">
Track your API usage to stay within limits:

```javascript
class RateLimitMonitor {
  constructor() {
    this.requests = new Map();
  }

  track(response) {
    const limit = response.headers.get('X-RateLimit-Limit');
    const remaining = response.headers.get('X-RateLimit-Remaining');
    const reset = response.headers.get('X-RateLimit-Reset');

    this.requests.set(Date.now(), {
      limit,
      remaining,
      reset,
    });

    // Clean up old data
    this.cleanup();
  }

  cleanup() {
    const now = Date.now();
    for (const [timestamp] of this.requests) {
      if (now - timestamp > 3600000) {
        // 1 hour
        this.requests.delete(timestamp);
      }
    }
  }

  getStats() {
    const latest = Array.from(this.requests.values()).pop();
    return {
      limit: latest?.limit,
      remaining: latest?.remaining,
      reset: latest?.reset,
      usage: this.requests.size,
    };
  }
}
```

</Accordion>
</AccordionGroup>

## Rate Limit Strategies

### Caching

Implement caching to reduce API calls:

```javascript
const cache = new Map();

async function cachedRequest(url, ttl = 3600000) {
  const cached = cache.get(url);
  if (cached && Date.now() - cached.timestamp < ttl) {
    return cached.data;
  }

  const data = await makeRequest(url);
  cache.set(url, {
    data,
    timestamp: Date.now(),
  });
  return data;
}
```

### Webhooks

For long-running operations, use webhooks instead of polling:

```javascript
const job = await fetch('https://api.weblinq.dev/v1/jobs', {
  method: 'POST',
  headers: {
    Authorization: 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    urls: ['https://example.com'],
    webhook: 'https://your-server.com/webhook',
  }),
});
```

## Increasing Your Limits

<Card title="Need Higher Limits?" icon="arrow-up-right">
  If you need higher rate limits: 1. **Upgrade Your Plan** - Higher tiers get higher limits - More concurrent requests -
  Priority queue access 2. **Enterprise Custom Limits** - Custom rate limits - Dedicated infrastructure - SLA guarantees
  [Contact Sales](mailto:sales@weblinq.dev)
</Card>

## Best Practices Summary

<Steps>
  <Step title="Monitor Your Usage">Track your API usage and stay well below limits</Step>

  <Step title="Implement Retries">Use exponential backoff with proper error handling</Step>

  <Step title="Optimize Requests">Batch requests and implement caching where possible</Step>

  <Step title="Use Webhooks">Prefer webhooks over polling for long operations</Step>
</Steps>

<Note>Need help with rate limits? Contact our [support team](/support/contact) for assistance.</Note>{' '}
